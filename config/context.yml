BeerPong-v0:
  algorithm: episodic_td3
  algo_params:
    initial_promp_params: 0.1
    actor_learning_rate: 0.0001
    critic_learning_rate: 0.0001
    total_timesteps: 6.e+6
    policy: MlpPolicy
    policy_type: off_policy
    action_noise_sigma: 0.5
    weight_noise_judge: False
    weight_noise: 0
    policy_kwargs:
      activation_fn: tanh
      pi: [64,64]
      qf: [256,256]
  promp_params:
    num_basis: 10
    zero_start: True
    zero_basis: 1
    controller_type: motor
    controller_kwargs:
      p_gains: [1.5, 5, 2.55, 3, 2., 2, 1.25]
      d_gains: [0.02333333, 0.1, 0.0625, 0.08, 0.03, 0.03, 0.0125]
    width: 0.01
    weight_scale: 1
  env_params:
    env_name: alr_envs:BeerPong-v0
    num_envs: 1

DeepMindBallInCupDenseContext-v0:
  algorithm: episodic_td3
  algo_params:
    initial_promp_params: 0.5
    actor_learning_rate: 0.000001
    critic_learning_rate: 0.0001
    total_timesteps: 6.e+7
    policy: MlpPolicy
    policy_type: off_policy
    action_noise_sigma: 0.5
    weight_noise_judge: False
    weight_noise: 0
    policy_kwargs:
      activation_fn: tanh
      pi: [ 256,256]
      qf: [ 256,256]
  promp_params:
    num_basis: 10
    zero_start: True
    zero_basis: 2
    controller_type: motor
    controller_kwargs:
      p_gains: 0.1
      d_gains: 0.1
    width: 0.025
    weight_scale: 100
  env_params:
    env_name: alr_envs:DeepMindBallInCupDenseContext-v0
    num_envs: 1
  eval_env:
    n_eval_episode: 10
    eval_freq: 10000


dmcCheetahDense-v0:
  algorithm: episodic_td3
  algo_params:
    initial_promp_params: 0.1
    actor_learning_rate: 0.0001
    critic_learning_rate: 0.0001
    total_timesteps: 6.e+6
    policy: MlpPolicy
    policy_type: off_policy
    action_noise_sigma: 0.5
    weight_noise_judge: False
    weight_noise: 0
    policy_kwargs:
      activation_fn: tanh
      pi: [ 64,64 ]
      qf: [ 256,256 ]
  promp_params:
    num_basis: 10
    zero_start: True
    zero_basis: 1
    controller_type: motor
    controller_kwargs:
      p_gains: 1
      d_gains: 0.1
    width: 0.01
    weight_scale: 1
  env_params:
    env_name: alr_envs:dmcCheetahDense-v0
    num_envs: 1


Meta-v2:
  algorithm: episodic_td3
  algo_params:
    initial_promp_params: 0.01
    actor_learning_rate: 0.0001
    critic_learning_rate: 0.0001
    total_timesteps: 6.e+6
    policy: MlpPolicy
    policy_type: off_policy
    action_noise_sigma: 0.5
    weight_noise_judge: False
    weight_noise: 0
    policy_kwargs:
      activation_fn: tanh
      pi: [64,64]
      qf: [256,256]
  promp_params:
    num_basis: 10
    zero_start: True
    zero_basis: 1
    controller_type: MetaWorld
    width: 0.01
    weight_scale: 1
  env_params:
    env_name: alr_envs
    num_envs: 1


HopperXYJumpMiddleContext-v0:
  algorithm: episodic_td3
  algo_params:
    initial_promp_params: 0.1
    actor_learning_rate: 0.0001
    critic_learning_rate: 0.0001
    total_timesteps: 6.e+6
    policy: MlpPolicy
    policy_type: off_policy
    noise_sigma: 0.1
    policy_kwargs:
      activation_fn: tanh
      pi: 256
      qf: 256
  promp_params:
    num_basis: 10
    zero_start: False
    zero_basis: 1
    controller_type: pid
    controller_kwargs:
      p_gains: 1
      d_gains: 0.1
      i_gains: 0
    width: 0.01
    weight_scale: 1
  env_params:
    env_name: alr_envs:HopperXYJumpMiddleContext-v0
    num_envs: 1


HopperXYJumpStepContext-v0:
  algorithm: episodic_td3
  algo_params:
    initial_promp_params: 0.1
    actor_learning_rate: 0.0001
    critic_learning_rate: 0.0001
    total_timesteps: 1.e+7
    policy: MlpPolicy
    policy_type: off_policy
    action_noise_sigma: 0.5
    weight_noise_judge: True
    weight_noise: 0
    policy_kwargs:
      activation_fn: tanh
      pi: 256
      qf: 256
  promp_params:
    num_basis: 10
    zero_start: False
    zero_basis: 1
    controller_type: pid
    controller_kwargs:
      p_gains: 1
      d_gains: 0.1
      i_gains: 0
    width: 0.01
    weight_scale: 0.01
  env_params:
    env_name: alr_envs:HopperXYJumpStepContext-v0
    num_envs: 1
